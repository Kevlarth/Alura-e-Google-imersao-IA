{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4Y9WO77330wiDoUApaPbs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kevlarth/Alura-e-Google-imersao-IA/blob/main/Projeto_Alura_%2B_Google_Imers%C3%A3o_Ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de Similaridade com Gemini Pro e Extração de Trechos Relevantes no Google Colab\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Este notebook utiliza o poder do Gemini Pro para calcular a similaridade entre um assunto e um artigo em PDF, além de extrair os trechos mais relevantes do artigo.\n",
        "\n",
        "## Passo 1: Instalação das bibliotecas"
      ],
      "metadata": {
        "id": "VU5qmxJjdkn-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PV7jAXtAddmn"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U PyPDF2 beautifulsoup4 nltk scikit-learn google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 2: Importação das bibliotecas"
      ],
      "metadata": {
        "id": "cPpIfHhbeYto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import PyPDF2\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8cpMnNUeadG",
        "outputId": "cb16ac50-f4e9-4d51-c9e1-61e59f2f9813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 3: Configuração da API Key do Gemini Pro\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Para manter a chave de API segura, usaremos o userdata do Colab.\n"
      ],
      "metadata": {
        "id": "f_dMvNWKedvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n"
      ],
      "metadata": {
        "id": "q8Wqh3iffWcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 4: Configuando o Model"
      ],
      "metadata": {
        "id": "1OIc8b0KZw4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    print(m.name)\n",
        "\n",
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0.7\n",
        "}\n",
        "\n",
        "safety_settings = {\n",
        "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
        "    \"HATE\": \"BLOCK_NONE\",\n",
        "    \"SEXUAL\": \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\": \"BLOCK_NONE\"\n",
        "}\n",
        "\n",
        "model = genai.GenerativeModel(model_name='models/gemini-1.5-pro-latest',\n",
        "                                  generation_config=generation_config,\n",
        "                                  safety_settings=safety_settings,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "JasO2hyqZ50H",
        "outputId": "90752b2e-5f59-462f-cf68-aa20e8c66f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-1.5-pro-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 5: Funções auxiliares"
      ],
      "metadata": {
        "id": "UKj9TV3ifaTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para extrair texto de um PDF\n",
        "def extract_text_from_pdf(pdf_url):\n",
        "  response = requests.get(pdf_url)\n",
        "  with open('temp.pdf', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "  pdf_reader = PyPDF2.PdfReader('temp.pdf')\n",
        "  text = \"\"\n",
        "  for page in pdf_reader.pages:\n",
        "    text += page.extract_text()\n",
        "  return text\n",
        "\n",
        "# Função para pré-processar o texto\n",
        "def preprocess_text(text):\n",
        "  text = text.lower()\n",
        "  text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "  text = \" \".join(nltk.word_tokenize(text))\n",
        "  return text\n",
        "\n",
        "# Função para gerar o resumo do artigo com Gemini Pro\n",
        "def summarize_with_gemini(text):\n",
        "    response = model.generate_content(f'Por favor, gere um resumo conciso e informativo do seguinte artigo:\\n\\n{text}')\n",
        "    summary = response.text\n",
        "    return summary\n",
        "\n",
        "# Função para calcular a similaridade lexical\n",
        "def calculate_lexical_similarity(text1, text2):\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "  similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
        "  return similarity\n",
        "\n",
        "# Função para identificar trechos relevantes\n",
        "def get_relevant_sentences(text, assunto, similarity_threshold=0.25):\n",
        "  sentences = nltk.sent_tokenize(text)\n",
        "  relevant_sentences = []\n",
        "  for sentence in sentences:\n",
        "    similarity = calculate_lexical_similarity(assunto, sentence)\n",
        "    if similarity >= similarity_threshold:\n",
        "      relevant_sentences.append(sentence)\n",
        "  return relevant_sentences"
      ],
      "metadata": {
        "id": "9pv1v9lGfbVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 6: Utilização\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;Agora você pode usar a função analisar_similaridade_pdf para analisar seus PDFs!"
      ],
      "metadata": {
        "id": "vYfCt9CNf3aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrada do usuário\n",
        "assunto = input(\"Digite o texto do assunto: \")\n",
        "pdf_url = input(\"Digite a URL do artigo em PDF: \")\n",
        "\n",
        "# Processamento\n",
        "text = extract_text_from_pdf(pdf_url)\n",
        "processed_text = preprocess_text(text)\n",
        "processed_assunto = preprocess_text(assunto)\n",
        "article_summary = summarize_with_gemini(processed_text)\n",
        "similarity = calculate_lexical_similarity(processed_assunto, article_summary)\n",
        "relevant_sentences = get_relevant_sentences(text, assunto)\n",
        "\n",
        "# Saída\n",
        "print(f\"\\nSimilaridade: {similarity:.2f}\")\n",
        "if relevant_sentences:\n",
        "    print(\"\\nTrechos relevantes:\")\n",
        "    for sentence in relevant_sentences:\n",
        "        print(f\"- {sentence}\")"
      ],
      "metadata": {
        "id": "ch4hts5_bL76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uQHx32OA19Gs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}